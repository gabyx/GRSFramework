# Default Job configuration file for render job

# WARNING:
# Take care that indentation needs to be made by tabulator character, because indentation by spaces will result in multiline arguments!
# Section and option names may contain the following characters [_a-zA-Z-], e.g ${Sec1-Sub1:Opt_1-32}

# Environment variables are prepended with 'ENV::'
# All key with value "will_be_generated" mark values which do not need to be defined yet because they will get generated automatically 
# Actually the value of these variables can be anything they just need to be defined

# The submit.py script defines on more additional variable:
#   General:modulePathJobGen   : This is the path to the jobGenerators module (where all standart templates can be found, for certain generators) 
#   General:currentWorkDir     : The directory where the submit.py has been executed (mainly submit.py is executed in the Job folder)

# All these options in section (Job and Template) are strictly needed by GeneratorMPIJob which inherits from Generator
# GeneratorMPI provides these additional parameters which can be referenced in all sections:
#   Job:jobIdx :   The index of the currently generated job
#   Job:submitCommand

[Job]

globalDir            = ENV::MYGLOBALSCRATCH_DIR/${Job:jobName}
localDir             = ENV::MYLOCALSCRATCH_DIR/${Job:jobName}

jobName              = ${Cluster:jobName}All-15.${Job:jobIdx}
scriptDirName        = Launch_${Job:jobName}
scriptDir            = ${Cluster:jobGeneratorOutputDir}/${Job:scriptDirName}

copyLocation         = 

submitArgs           = -W ${Cluster:runTime} -J "${Job:jobName}" -n ${Cluster:nProcesses} -R rusage[scratch=${Cluster:localScratchPerCore},mem=${Cluster:ramPerCore}] -oo "${Job:scriptDir}/lsf${Cluster:jobName}" < ${Job:scriptDir}/launch.sh 
submitCommand        =  will_be_generated

executableCommand    =  will_be_generated

processIdxVariabel   = $${OMPI_COMM_WORLD_RANK}
processDir           = ${Job:localDir}/Process_${Job:processIdxVariabel}

statusFolder         = ${General:currentWorkDir}/ENV::USER/global/${Cluster:jobName}

# Check files/executables
pathChecker             = [ ${Pipeline:simFiles15}]
executableChecker       = [ ["['Pipeline']['executableConverter']" , "${Pipeline:executableConverter}"] ]
# =====================================================

# All these files listed under this section are first replaced with the variables defined here and by the generator
# and the output is written to the jobs script directory folder by default.
# To each template defined here two additional options are generated if they do not yet exist!
# TempaltesOut:myTemplate  : The output path of the template ${Templates:myTemplate}
# The default path is the the job script directory ${Job:scriptDir}/basename(${Templates:myTemplate})

[Templates]

pipelineSpecs           = ${General:currentWorkDir}/templates/PipelineSpecs.json


launch                  = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/launch.sh 
startJob                = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/generatorToolPipeline/templates/start.sh
preProcessPerNode       = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/preProcess.sh
processPerCore          = ${General:currentWorkDir}/templates/process.sh
postProcessPerNode      = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/postProcess.sh
endJob                  = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/generatorToolPipeline/templates/end.sh

submitJob               = ${General:configuratorModuleDir}/jobGenerators/templates/submit.sh

gridderLogic            =  { "inputFile" : "${General:currentWorkDir}/gridderLogic/GridExtractionLogic.xml" , "outputFile" : "${Pipeline:converterLogic}" , "configurator" : { "modulePath" : "${General:configuratorModuleDir}/jobGenerators/dictionaryAdjuster.py" , "moduleName" : "dictionaryAdjuster" , "className" : "DictionaryAdjuster" }, "settings" : {"additionalFiles" : [{"path":"${General:currentWorkDir}/data/ExperimentSettings.json" , "parentName":"expSettings"}] } }

[TemplatesOut]
gridderLogic = ${Job:scriptDir}/GridExtractionLogic.xml 

# All these options in section (RigidBodySim) are strictly needed by GeneratorMPIJobRigidBody which inherits from GeneratorMPIJob
# GeneratorRigidBodyRender provides these automatic generated additional parameters which can be referenced in all sections:
# 	None
# Principally, every stuff here can be moved into PipelineSpecs.json ....


[Pipeline-PreProcess]

fileMoverProcessFile     = ${Job:scriptDir}/FileMoverSequence-Rank-{0:04d}.json
fileMoverAdditionalTasks = [ ]
fileMoverLinkAllTools    = true 

# if we generate multiple jobs this path indicated where the status file is found (for first job this string is empty)
# set from the file validation output of last's job post-process
validationInfoFile    = will_be_generated



[Pipeline]

# Standart pipeline values ============================
pipelineSpecs           = ${Job:scriptDir}/PipelineSpecs.json

cleanUpCommand  = 

# Input Remover
inputRemoverCommand     =  find ${Job:processDir} -type d -name *input* | xargs rm -r

# Frame Generation =====================================
frameGenerator          = { "modulePath":"${General:currentWorkDir}/scripts/frameGenerator.py" , "moduleName":"frameGenerator",  "className":"FrameGenerator" }
# ======================================================

# Converter =========================================================================
executableConverter     = ENV::SIMCONV
asanMangler             = ENV::ASANMANGLER

# local dirs
converterDir            = converter
converterExecutionDir   = ${Pipeline:converterDir}
converterInputDir       = ${Pipeline:converterExecutionDir}/input
converterOutputDir      = ${Pipeline:converterExecutionDir}/output

# gets configured!
converterLogic          = ${TemplatesOut:gridderLogic} 

sceneFile               = ${General:currentWorkDir}/data/SceneFile.xml
mediaDir                = ENV::ROOT_REPO_DIR/SourceCode/Projects/SimulationFramework/Projects/media

# number of state to extract 
# for each study, extractStateCount grids are extracted, starting the entryStateIdx
# the stateStepSize is determined by min(finalStateIdx-entryStateIdx,over all Studies) / extractStateCount
# and is the same for all studies
extractStateCount    = 10000000
studyEntryDataFile   = ${General:currentWorkDir}/data/StudyEntryData.json

# the first 3 studies (mu=0-0.3) are no relevant for extracting grid
#simFiles0            = [ "${General:currentWorkDir}/data/SimState-P-0-0.sim" ] 
#simFiles1            = [ "${General:currentWorkDir}/data/SimState-P-1-0.sim" ] 
#simFiles2            = [ "${General:currentWorkDir}/data/SimState-P-2-0.sim" ] 
#simFiles3            = [ "${General:currentWorkDir}/data/SimState-P-3-0.sim" ] 
#simFiles4            = [ "${General:currentWorkDir}/data/SimState-P-4-0.sim" ] 
#simFiles5            = [ "${General:currentWorkDir}/data/SimState-P-5-0.sim" ] 
#simFiles6            = [ "${General:currentWorkDir}/data/SimState-P-6-0.sim" ] 
#simFiles7            = [ "${General:currentWorkDir}/data/SimState-P-7-0.sim" ] 
#simFiles8            = [ "${General:currentWorkDir}/data/SimState-P-8-0.sim" ] 
#simFiles9            = [ "${General:currentWorkDir}/data/SimState-P-9-0.sim" ] 
#simFiles10           = [ "${General:currentWorkDir}/data/SimState-P-10-0.sim" ] 
#simFiles11           = [ "${General:currentWorkDir}/data/SimState-P-11-0.sim" ] 
#simFiles12           = [ "${General:currentWorkDir}/data/SimState-P-12-0.sim" ] 
#simFiles13           = [ "${General:currentWorkDir}/data/SimState-P-13-0.sim" ] 
#simFiles14           = [ "${General:currentWorkDir}/data/SimState-P-14-0.sim" ]
simFiles15           = [ "${General:currentWorkDir}/data/SimState-P-15-2.sim","${General:currentWorkDir}/data/SimState-P-15-3.sim" ,"${General:currentWorkDir}/data/SimState-P-15-4.sim" ,"${General:currentWorkDir}/data/SimState-P-15-5.sim" ,"${General:currentWorkDir}/data/SimState-P-15-6.sim" ,"${General:currentWorkDir}/data/SimState-P-15-7.sim", "${General:currentWorkDir}/data/SimState-P-15-8.sim" ]

#frame0               = { "outputFile" : "output/GridVelocity-P-0/GridFile", "studyNr" : 0 , "simFiles" : ${Pipeline:simFiles0} }
#frame1               = { "outputFile" : "output/GridVelocity-P-1/GridFile", "studyNr" : 1 , "simFiles" : ${Pipeline:simFiles1} }
#frame2               = { "outputFile" : "output/GridVelocity-P-2/GridFile", "studyNr" : 2 , "simFiles" : ${Pipeline:simFiles2} }
#frame3               = { "outputFile" : "output/GridVelocity-P-3/GridFile", "studyNr" : 3 , "simFiles" : ${Pipeline:simFiles3} }
#frame4               = { "outputFile" : "output/GridVelocity-P-4/GridFile", "studyNr" : 4 , "simFiles" : ${Pipeline:simFiles4} }
#frame5               = { "outputFile" : "output/GridVelocity-P-5/GridFile", "studyNr" : 5 , "simFiles" : ${Pipeline:simFiles5} }
#frame6               = { "outputFile" : "output/GridVelocity-P-6/GridFile", "studyNr" : 6 , "simFiles" : ${Pipeline:simFiles6} }
#frame7               = { "outputFile" : "output/GridVelocity-P-7/GridFile", "studyNr" : 7 , "simFiles" : ${Pipeline:simFiles7} }
#frame8               = { "outputFile" : "output/GridVelocity-P-8/GridFile", "studyNr" : 8 , "simFiles" : ${Pipeline:simFiles8} }
#frame9               = { "outputFile" : "output/GridVelocity-P-9/GridFile", "studyNr" : 9 , "simFiles" : ${Pipeline:simFiles9} }
#frame10              = { "outputFile" : "output/GridVelocity-P-10/GridFile", "studyNr" : 10 , "simFiles" : ${Pipeline:simFiles10} }
#frame11              = { "outputFile" : "output/GridVelocity-P-11/GridFile", "studyNr" : 11 , "simFiles" : ${Pipeline:simFiles11} }
#frame12              = { "outputFile" : "output/GridVelocity-P-12/GridFile", "studyNr" : 12 , "simFiles" : ${Pipeline:simFiles12} }
#frame13              = { "outputFile" : "output/GridVelocity-P-13/GridFile", "studyNr" : 13 , "simFiles" : ${Pipeline:simFiles13} }
#frame14              = { "outputFile" : "output/GridVelocity-P-14/GridFile", "studyNr" : 14 , "simFiles" : ${Pipeline:simFiles14} }
frame15              = { "outputFile" : "output/GridVelocity-P-15/GridFile", "studyNr" : 15 , "simFiles" : ${Pipeline:simFiles15} }

# each dict is one frame (which get distributed over all processes)
frameList               = [ ${Pipeline:frame15} ]


# Format string: 0: argument is stateIdx, 1: time, 2: frameIdx
converterProcessFileWriter = { "modulePath":"${General:currentWorkDir}/scripts/processFileWriter.py" , "moduleName":"processFileWriter",  "className":"ConverterProcessFileWriter" }
converterProcessFile    = ${Job:scriptDir}/ConverterSequence-Rank-{0:04d}.xml




[Pipeline-PostProcess]

# Post-process: assemble file validation
validationSearchDir       = ${Job:globalDir}
validationInfoFile        = ${Job:scriptDir}/FileInfo.json
statusFolder              = ${General:currentWorkDir}/ENV::USER/global/${Cluster:jobName}
