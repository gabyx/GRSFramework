[Job]

globalDir            = ENV::MYGLOBALSCRATCH_DIR/${Cluster:jobName}${Job:jobTitle}/${Job:jobName}
localDir             = ENV::MYLOCALSCRATCH_DIR/${Job:jobName}

jobTitle             = -P-9
jobName              = ${Cluster:jobName}${Job:jobTitle}.${Job:jobIdx}

scriptDirName        = Launch_${Job:jobName}
scriptDir            = ${Cluster:jobGeneratorOutputDir}/${Job:scriptDirName}

copyLocation         = 

submitArgs           = -W ${Cluster:runTime} -J "${Job:jobName}" -n ${Cluster:nProcesses} -R rusage[scratch=${Cluster:localScratchPerCore},mem=${Cluster:ramPerCore}] -oo "${Job:scriptDir}/lsf${Cluster:jobName}" < ${Job:scriptDir}/launch.sh 
submitCommand        =  will_be_generated

executableCommand    =  will_be_generated

processIdxVariabel   = $${OMPI_COMM_WORLD_RANK}
processFolderName    = Process_${Job:processIdxVariabel}
processDir           = ${Job:localDir}/${Job:processFolderName}

# Check files/executables
pathChecker             = [ ${Pipeline:simFiles9}]
executableChecker       = [ ["['Pipeline']['executableConverter']" , "${Pipeline:executableConverter}"] ]
# =====================================================

[Templates]

pipelineSpecs           = ${General:jobDir}/templates/PipelineSpecs.json


launch                  = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/launch.sh 
startJob                = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/generatorToolPipeline/templates/start.sh
preProcessPerNode       = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/preProcess.sh
processPerCore          = ${General:jobDir}/templates/process.sh
postProcessPerNode      = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/templates/postProcess.sh
endJob                  = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/generatorToolPipeline/templates/end.sh

endPerProcess           = ${General:configuratorModuleDir}/jobGenerators/jobGeneratorMPI/generatorToolPipeline/templates/endPerProcess.sh

submitJob               = ${General:configuratorModuleDir}/jobGenerators/templates/submit.sh

gridderLogic            =  { "inputFile" : "${General:currentWorkDir}/gridderLogic/GridExtractionLogic.xml" , "outputFile" : "${Pipeline:converterLogic}" , "configurator" : { "modulePath" : "${General:configuratorModuleDir}/jobGenerators/dictionaryAdjuster.py" , "moduleName" : "dictionaryAdjuster" , "className" : "DictionaryAdjuster" }, "settings" : {"additionalFiles" : [{"path":"${General:currentWorkDir}/data/ExperimentSettings.json" , "parentName":"expSettings"}] } }

[TemplatesOut]
gridderLogic = ${Job:scriptDir}/GridExtractionLogic.xml 


[Pipeline-PreProcess]

fileMoverProcessFile     = ${Job:scriptDir}/FileMoverSequence-Rank-{0:04d}.json
fileMoverAdditionalTasks = [ ]
fileMoverLinkAllTools    = true 

# if we generate multiple jobs this path indicated where the status file is found (for first job this string is empty)
# set from the file validation output of last's job post-process
validationInfoFile    = will_be_generated



[Pipeline]

# Standart pipeline values ============================
pipelineSpecs           = ${Job:scriptDir}/PipelineSpecs.json

cleanUpCommand  = 

# Input Remover
inputRemoverCommand     =  find ${Job:processDir} -type d -name *input* | xargs rm -r

# File validation per Process
validationInfoFile        = ${Job:processDir}/FileInfo.json

# Frame Generation =====================================
frameGenerator          = { "modulePath":"${General:jobDir}/scripts/frameGenerator.py" , "moduleName":"frameGenerator",  "className":"FrameGenerator" }
# ======================================================

# Converter =========================================================================
executableConverter     = ENV::GRSF_SIMCONV
asanMangler             = ENV::ASANMANGLER

# local dirs
converterDir            = converter
converterExecutionDir   = ${Pipeline:converterDir}
converterInputDir       = ${Pipeline:converterExecutionDir}/input
converterOutputDir      = ${Pipeline:converterExecutionDir}/output

# gets configured!
converterLogic          = ${TemplatesOut:gridderLogic} 

sceneFile               = ${General:currentWorkDir}/data/SceneFile.xml
mediaDir                = ENV::GRSF_MEDIA_DIR

# number of state to extract 
# for each study, extractStateCount grids are extracted, starting the entryStateIdx
# the stateStepSize is determined by min(finalStateIdx-entryStateIdx,over all Studies) / extractStateCount
# and is the same for all studies
extractStateCount    = 10000000
# this is only a dummy entry data test!
studyEntryDataFile   = ${General:jobDir}/data/StudyEntryDataP-9Test.json


simFiles9            = [ "${General:currentWorkDir}/data/SimState-P-9-0.sim" ] 
frame9               = { "outputFile" : "output/GridVelocity-P-9/GridFile", "studyNr" : 9 , "simFiles" : ${Pipeline:simFiles9} }

# each dict is one frame (which get distributed over all processes)
frameList               = [ ${Pipeline:frame9} ]


# Format string: 0: stateIdx, 1: time, 2: frameIdx
converterProcessFileWriter = { "modulePath":"${General:jobDir}/scripts/processFileWriter.py" , "moduleName":"processFileWriter",  "className":"ConverterProcessFileWriter" }
converterProcessFile    = ${Job:scriptDir}/ConverterSequence-Rank-{0:04d}.xml

[Pipeline-PostProcess]

# for parallel validation in end.sh ====================================
validationSearchDirProcess = ${Job:globalDir}/${Job:processFolderName}
validationInfoFileProcess    = ${Job:globalDir}/${Job:processFolderName}/FileInfo.json
# validation output file
validationInfoFile        = ${Job:globalDir}/FileInfo.json
validationInfoFilesCombineGlob = ${Job:globalDir}/**/Process**/FileInfo.json
# ======================================================================

# assemble file validation (manual)
validationSearchDirAll       = ${Job:globalDir}


statusFolder              = ENV::MYGLOBALSCRATCH_DIR/${Cluster:jobName}${Job:jobTitle}
